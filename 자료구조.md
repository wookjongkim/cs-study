<details markdown = "1">
<summary>자료구조와 알고리즘에 대해 설명해주세요</summary>
자료구조는 데이터를 원하는 규칙 또는 목적에 맞게 저장하기 위한 구조이고<br>
알고리즘이란 자료구조에 쌓인 데이터를 활용해 어떠한 문제를 해결하기 위한 여러 동작들의 모임을 의미합니다.<br>
</details>

<details markdown = "1">
<summary>Java Collection Framework란 무엇인가요?</summary>
<img src = "https://github.com/wookjongkim/cs-study/assets/121083077/46cd973e-01d2-47ca-9e69-266018f5df97">
컬렉션 프레임워크란 다수의 데이터를 쉽고 효과적으로 처리할 수 있는 표준화된 방법을 제공하는 클래스들의 집합을 의미합니다.<br>
이러한 컬렉션 프레임워크는 Collection 인터페이스와 Map인터페이스로 나뉘며, Collection 인터페이스 하위에는 List,Queue,Set 인터페이스가 있습니다.<br>
<br>
참고 - 객체만 담을 수 있고, 이는 객체의 주소를 담는 것이기에 null도 저장 가능<br>
</details>

<details markdown = "1">
<summary>배열과 ArrayList가 무엇인지</summary>
배열이란 동일한 데이터 타입의 값들을 연속된 메모리 공간에 저장하는 자료구조이며, 크기를 동적으로 변경할 수 없습니다.<br>
이러한 배열의 요소는 메모리에 연속적으로 저장되며, 각 요소는 고유한 인덱스를 가지므로 Random Access가 가능합니다.(물리적 저장순서와 논리적 저장순서가 일치하기에 인덱스 통해 빠르게 접근)<br>
배열은 데이터 개수가 정해져있고, 접근이 빈번할 경우 사용하기 좋은 자료구조이나, 중간에 요소가 삽입되거나 삭제되는 경우엔 적합하지 않는 자료구조입니다.<br>
또한 배열은 공간 지역성이 보장되어 요소 접근 시 Cache hit 가능성이 커 캐시의 효율성을 높일 수 있습니다.<br>
<br><br>
ArrayList는 동일한 데이터 타입의 값들을 연속된 메모리 공간에 저장하며, 크기를 동적으로 변경할 수 있는 자료구조입니다.(요소 추가 시 동적으로 크기 증가)<br>
ArrayList는 내부적으로 데이터를 (Object[])배열에 저장하고 있어, 각 요소가 인덱스를 가지고 있고, 이를 바탕으로 Random Access가 가능합니다.<br>
ArrayList는 데이터 개수가 정해져 있지 않고, 접근이 빈번할 경우 사용하기 좋은 자료구조입니다.<br>
이 또한 공간지역성이 보장되어 요소 접근 시 Cache hit 가능성이 커 캐시의 효율성을 높일 수 있습니다.<br>
<br><br>
참고<br>
Random Access란 데이터의 특정 위치에 직접 접근할 수 있는 것을 의미, 메모리 상 시작 주소 + (인덱스 x 데이터 타입 크기(참조형 변수 크기 4byte))를 통해 해당 인덱스 빠르게 접근 가능<br>
공간지역성이란, 관련된 데이터들이 연속적인 메모리 주소에 위치하면 그 데이터를 빠르게 읽거나 쓸수 있다.<br>
캐시 히트는 필요한 데이터가 캐시에 있다면 캐시에서 빠르게 데이터를 가져오는 것을 의미, 캐시 히트 가능성이 높다는 것은 캐시에서 이 데이터를 찾을 확률이 높다는 것<br>
<br>
배열의 시간복잡도<br>
접근(O(1)) : 배열의 특정 인덱스에 위치한 요소에 바로 접근 가능<br>
삽입(O(n)) : 중간에 요소를 삽입하려면 이후의 모든 요소를 하나씩 밀어야 함<br>
삭제(O(n)) : 중간의 요소를 삭제하려면 이후의 모든 요소를 하나씩 당겨야 합니다.<br>
검색(O(n)) : 특정 요소를 찾기 위해서는 순차적으로 검색을 해야 함<br>
<br>
ArrayList도 접근은 O(1), 삽입의 경우 빈자리가 있을때 맨 끝에 추가한다면 O(1)<br>
내부가 꽉찼을때 끝에 추가할때는 O(N), 중간의 경우 당연히 O(N)<br>
삭제의 경우 삭제 뒤에 애들을 앞으로 떙겨야 하기에 O(n), 근데 마지막 값을 지운다면 O(1)일듯<br>
<br>
차이를 물어보면 배열의 경우 한번 생성되면 크기를 변경할 수 없는 반면, ArrayList는 동적으로 크기가 조절됨. 요소를 추가하거나 제거할때 자동으로 크기가 변경됨<br>
</details>

<details markdown = "1">
<summary>캐시의 효율성에 대해 설명해주세요.</summary>
CPU는 필요한 데이터를 RAM에서 가져올 수 있지만, 이렇게 직접 데이터를 읽는 것은 상대적으로 느립니다.<br>
이를 위해 훨씬 빠른 속도를 가진 메모리인 캐시를 사용하며, 필요한 데이터가 캐시에 있다면 캐시에서 빠르게 데이터를 가져올 수 있는데 이를 캐시히트가 발생되었다고 합니다.<br>
하지만 캐시의 크기는 매우 작기에, 모든 데이터를 저장할 수 없고, CPU는 어떤 데이터를 캐시에 저장할지 결정하는데 이때 중요한 원칙이 공간지역성입니다.<br>
이는 메모리에 인접한 위치에 있는 데이터는 함께 사용될 가능성이 높다는 원리인데, 배열의 경우 모든 요소가 메모리 상 연속적으로 위치해있습니다.<br>
따라서 한번에 여러 요소를 캐시에 저장할 수 있고, 이후 배열에 접근할때 빠른 속도를 얻을 수 있습니다.<br>
요약하자면 배열의 요소들은 메모리상에 인접해 있기때문에, 한번에 여러 요소를 캐시에 저장할 수 있고, 그래서 CPU가 배열의 데이터에 빠르게 접근할 수 있습니다.<br>
<br><br><br>
참고 - 컴퓨터에서 데이터를 읽을때, 주소가 연속적인 메모리 위치에 있는 데이터를 읽는 것이 흩어진것 보다 효과적<br>
왜냐하면 컴퓨터는 메모리에서 블록 단위로 데이터를 읽음. 따라서 배열과 같이 데이터가 연속적인 메모리 위치에 있으면, 컴퓨터는 한번에 여러데이터 읽을 수 있따.<br>
이것이 한번에 여러 요소를 캐시에 저장할 수 있다는 의미.<br>
데이터가 메모리의 여러 위치에 있으면, 컴퓨터는 여러 블록을 읽어야 함(접근하는데 더 많은 시간이 듬)<br>
연관 데이터를 가능한 가까이 두는것이 캐시를 효율적으로 사용하고 성능을 높이는데 사용<br>
캐시 라인을 기반으로 읽어옴 예를들어 arr[0]이 캐시에 로드되면,arr[1],arr[2]등 같은 캐시라인에 있는 배열 요소도 같이 캐시에 로드됨<br>
즉 cpu가 램에서 데이터를 가져올때 캐시 라인 단위로 가져옴(일반적으로 64바이트)<br>
따라서 cpu가 arr[0]의 값을 가져올때 캐시는 arr[0]을 포함하는 메모리 블록을 가져오며 여기엔 arr[0]제외 인접 데이터들도 포함됨<br>
따라서 arr[1],arr[2]는 캐시에 저장되고 나중에 접근할때는 RAM에 접근할 필요 X<br>
</details>

<details markdown = "1">
<summary>LinkedList에 대해 아시는 대로 설명해주세요.</summary>
LinkedList란 각 노드가 데이터와 포인터를 가지고 연결되어 있는 방식으로 데이터를 저장하는 자료구조입니다.<br>
이러한 링크드 리스트의 종류로는 단방향, 양방향, 원형 링크드리스트들이 존재합니다.<br>
LinkedList의 각 요소는 메모리상에 불연속적으로 배치되어 있습니다.<br>
따라서 특정 인덱스 요소에 접근하려면 ArrayList와 다르게 순차적으로 하므로 접근에 최적화된 자료구조는 아닙니다<br>
하지만 삽입 삭제가 빈번하게 일어나는 경우에는 유용한 자료구조이며, CPU 스케쥴링이나 메모리 관리 등에서 사용되는<br>
큐나 스택등의 자료구조를 구현하는데 사용될 수 있습니다.<br>
</details>

<details markdown = "1">
<summary>ArrayList와 LinkedList의 차이에 대해 설명해주세요.</summary>
ArrayList는 동적 배열의 형태를 가지고 있어, 데이터가 메모리 상에서 연속적으로 배치됩니다.<br>
이로 인해 인덱스를 통해 빠르게 요소에 접근하는 것이 가능합니다. 이를 'random access'라고 합니다.<br>
그러나 이런 특성 때문에 중간에 새로운 요소를 삽입하거나 기존 요소를 삭제할 때는 배열의 요소들을 이동시키는 추가적인 작업이 필요합니다<br>
.이는 비효율적일 수 있습니다. 또한, 배열이 꽉 차면 크기를 늘려야 하며 이 과정에서도 시간이 소요됩니다. 하지만 ArrayList의 공간 지역성이 보장되므로, 캐시 히트 가능성이 높아져서 캐시의 효율성이 좋습니다.<br>
<br>
반면, LinkedList는 연결 리스트의 형태를 가지며, 각 요소가 메모리 상에서 불연속적으로 배치됩니다.<br>
이로 인해 인덱스를 통한 빠른 접근이 어렵습니다. 대신, LinkedList는 노드의 연결 정보만 변경함으로써 요소의 삽입과 삭제를 매우 효율적으로 수행할 수 있습니다.<br>
특히, 리스트의 시작 부분(head)나 끝 부분(tail)에서의 삽입 및 삭제는 매우 빠릅니다.<br>
그러나 LinkedList는 공간 지역성이 보장되지 않아 캐시 히트 가능성이 낮으며, 이로 인해 캐시의 효율성이 상대적으로 떨어집니다.<br>
<br>
요약하자면, 요소의 접근이 주로 이루어지는 경우에는 ArrayList를, 요소의 삽입과 삭제가 빈번하게 이루어지는 경우에는 LinkedList를 사용하는 것이 더 효율적일 수 있습니다."<br>
<br>
참고 - ArrayList 값 연속정 저장 : Random Access, LinkedList는 값이 산재되어 저장되어 있음<br>
첫번째 위치에 insert/remove DoublyLinkedList의 경우 O(1), ArrayList의 경우 O(N)<br>
마지막 위치에 insert/remove DoubleLinkedList의 경우 O(1), ArrayList의 경우 O(1) or O(N)<br>
중간에 insert/remove Doubly : O(N) or searchtime + O(1), ArrayList : O(N)<br>
값으로 search는 둘다 O(N)이지만 ArrayList가 나음<br>
인덱스로 값을 get, LinkedList의 경우 O(N), ArrayList의 경우 O(1)<br>
값으로 remove 시 둘다 O(N)<br>
</details>

<details markdown = "1">
<summary>왜 ArrayList의 캐시 효율성이 더 좋은지 가능한 상세히 설명해주세요</summary>
공간 지역성(spatial Locality)는 컴퓨터 프로그램에서 사용하는 데이터가 메모리의 특정 구간에 집중되어 있는 경향을 말합니다.<br>
즉, 한번 참조된 데이터 근처의 데이터가 곧 이어서 참조될 가능성이 높다는 의미이며, 이는 CPU 캐시의 설계와 밀접한 관계가 있습니다.<br>
CPU 캐시는 주기억장치(RAM)에 비해 매우 빠른 속도를 가지지만 그만큼 용량이 작아서 전체 메모리를 저장할 순 없습니다.<br>
따라서 CPU는 프로그램이 주로 참조하는 데이터를 캐시에 저장합니다. 이때 공간지역성이 있다면 한번 참조된 데이터 주변의 데이터가<br>
곧 이어서 참조될 가능성이 높으므로 이러한 데이터를 캐시에 미리 가져와 놓으면 메모리 접근 시간을 줄일 수 있습니다.<br>
ArrayList는 메모리 상에서 연속적인 데이터를 저장하는 구조를 가지고 있습니다. 따라서 한 데이터가 CPU 캐시에 로드되면 그 근처의 데이터도 함께 로드되게 됩니다.<br>
이후 이 근처의 데이터에 접근하게 되면, 이미 캐시에 데이터가 존재하므로 캐시 히트가 발생하고, 메모리 접근 시간이 크게 줄어듭니다.<br>
반면 LinkedList는 노드들이 메모리의 여기저기에 분산되어 저장됩니다.<br>
각 노드는 자신의 다음 노드에 대한 참조만을 가지고 있으며, 이 참조는 메모리상의 아무 곳에나 위치할 수 있습니다.<br>
따라서 한 노드를 참조했다고 해서 그 근처의 노드가 곧바로 참조될 확률이 낮습니다. 이것이 LinkedList에서 공간지역성이 보장되지 않는 이유입니다.<br>
이로 인해 LinkedList를 사용할때는 캐시 히트 가능성이 상대적으로 낮아지고, 이에 따라 캐시의 효율성이 떨어집니다.<br>
</details>

<details markdown = "1">
<summary>Array와 LinkedList의 차이점에 대해 설명해주세요</summary>
이둘의 주요 차이점은 데이터가 메모리에 저장되는 방식과 각 요소에 대한 접근 방식에 있습니다<br>
배열은 'Random Access'를 지원합니다. 이는 배열의 요소들이 메모리 상에서 연속적으로 위치하기 때문에 가능한 것입니다<br>
따라서, 인덱스를 통해 배열의 특정 요소에 직접 접근할 수 있으며, 이러한 접근은 일정한 시간복잡도인 O(1)를 가집니다<br>
반면에 LinkedList는 'Sequential Access'를 지원합니다. LinkedList의 요소들은 메모리 상의 임의의 위치에 있으며, 각 요소(노드)는 다음 요소를 가리키는 링크를 가지고 있습니다<br>
이 링크를 따라가면서 요소에 접근해야 하기 때문에, 특정 요소에 접근하는 데는 시간복잡도 O(N)이 소요됩니다<br>
배열에서 요소의 삽입 또는 삭제는 복잡한 작업입니다. 배열은 고정된 크기를 가지므로, 삽입 또는 삭제를 위해서는 배열의 크기를 조정하거나, 요소들을 재배치해야 합니다. <br>
이러한 작업은 시간복잡도 O(N)이 소요됩니다.<br>
반면에 LinkedList에서는 삽입 및 삭제 작업이 상대적으로 간단합니다. 특정 위치에 삽입 또는 삭제를 위해서는 단지 몇 개의 링크를 조정하면 되므로, 이 작업은 일반적으로 시간복잡도 O(1)을 가집니다.<br>
배열은 '정적 메모리 할당'을 사용합니다. 즉, 배열이 생성될 때 그 크기가 고정되며, 메모리 상에 연속적으로 할당됩니다. 따라서, 배열의 크기는 변경할 수 없습니다.<br>
반면에 LinkedList는 '동적 메모리 할당'을 사용합니다. LinkedList의 요소(노드)는 필요에 따라 생성되고, 각 노드는 메모리 상의 임의의 위치에 할당됩니다. 이러한 특성 덕분에 LinkedList는 필요에 따라 크기를 동적으로 변경할 수 있습니다."<br>
<br>
참고 -  배열은 스택 영역에 할당되고, LinkedList는 힙 영역에 할당되는 것이 일반적입니다.
</details>

<details markdown = "1">
<summary>스택과 큐의 차이점에 대해 설명해주세요</summary>
스택은 세로로된 바구니와 같은 구조로, 자료가 쌓이는 구조를 가지고 있습니다.<br>
이것은 Last in First out 특성을 가지고 있어, 가장 나중에 넣은 데이터를 가장 먼저 꺼내게 됩니다.<br>
큐는 가로로된 통과 같은 구조로, 데이터가 한쪽 방향으로만 흐르는 구조를 가지고 있습니다.<br>
이는 First in First Out 특성을 가지고 있어, 가장 먼저 넣은 데이터를 가장 먼저 꺼냅니다.<br>
<br><br>
참고 - LinkedList는 노드를 앞이나 뒤에 추가시 제거하는 시간이 상수 시간에 가능<br>
이러한 스택은 배열로 구현하는 경우, 데이터를 제거할때 실제 데이터를 지울 필요가 없고, top 인덱스를 지우는 것만으로도<br>
데이터의 삽입과 삭제를 효과적으로 관리할 수 있습니다.<br>
이러한 큐는 배열로 구현하게 되면 데이터를 제거할때마다 남은 데이터를 앞으로 당겨야 하는 비효율성이 있습니다.<br>
따라서 LinkedList와 같이 삽입 삭제가 용이한 자료구조로 구현하는것이 일반적입니다.<br>
</details>

<details markdown = "1">
<summary>힙에 대해 아시는 대로 설명해주세요.</summary>
힙은 최솟값 또는 최대값을 빠르게 찾아내기 위해 완전 이진트리 형태로 만들어진 자료구조입니다.<br>
힙에는 최대힙과 최소힙 두가지 유형이있습니다.<br> 
최대힙에서는 부모의 노드값이 그 자식 노드값보다 항상 크거나 같습니다.<br>
그리고 최소힙에서는 부모의 노드 값이 그 자식 노드값 보다 항상 작거나 같습니다.
이러한 힙을 사용하면 데이터 최댓값 또는 최솟값을 상수시간에 찾아낼 수 있으며, 삽입과 삭제는 로그 시간에 할 수 있기에 효율적입니다.<br>
<br>
참고<br>
이진트리 - 모든 노드의 최대 차수를 2로 제한한것<br>
완전(complete) 이진트리 - 모든 노드의 최대 차수 2 제한 + 마지막 레벨을 제외한 모든 노드 채워져 + 모든 노드는 왼쪽부터 채워져야함<br>
포화이진트리(perfect binary tree) 이진트리 - 완전 이진 트리 조건 + 마지막 레벨을 제외한 모든 노드는 두개의 자식 노드를 가짐<br>
상수시간 - 데이터 크기와 무관하게 일정한 시간을 필요로 한다는 것<br>
예를들어 배열에서 특정 인덱스의 값을 읽는 작업은 배열의 크기와 상관없이 항상 동일한 시간이 소요됨<br>
보통 배열로 구현하는 것이 효율적<br>
</details>

<details markdown = "1">
<summary>왜 힙의 삽입,삭제 연산의 시간복잡도는 O(logN)인지 설명해주세요.</summary>
힙은 완전 이진 트리의 형태를 띄고있기에 노드의 수가 늘어남에 따라 트리의 높이는 logN에 비례합니다(각 레벨에서 노드의 수가 두배로 늘어나므로 log에 비례)<br>
힙에서 삽입 및 삭제 연산은 루트 노드에서 시작하여 leaf 노드까지의 경로를 따라 이루어집니다.<br>
이 때문에 이러한 연산들은 트리에 높이에 비례하는 시간이 걸리며 이로인해 삽입 삭제 연산은 O(logN)이됩니다.<br>
<br><br>
예를 들어 삽입 연산의 경우 새로운 요소는 처음에 트리의 가장 하위 레벨(leaf노드)에 추가되고,그 후 힙 속성을 유지하며 적절한 위치로 이동합니다.<br>
이러한 연산은 새 요소를 부모 노드와 비교하며 진행되므로, 트리의 높이만큼의 비교가 이루어집니다.<br>
힙에서 가장 크거나 작은 요소를 삭제하면 일반적으로 루트 노드가 삭제됩니다.<br>
이후 트리의 가장 하위 레벨에서 하나의 노드를 루트로 이동시키고, 이 노드를 자식과 비교하며 적절한 위치로 이동시킵니다.<br>
이러한 연산 또한 트리의 높이에 비례하는 시간이 걸립니다.<br>
</details>

<details markdown = "1">
<summary>우선순위큐가 무엇인지와 동작원리에 대해 설명해주세요.</summary>
우선 순위 큐란 각각의 요소들이 우선순위를 가지고 있고, 요소들의 대기열에서 우선순위가 높은 요소가 우선순위가 낮은 요소보다 먼저 제공되는 자료구조입니다.<br>
우선순위 큐는 자료를 추가하는 작업과, 삭제하는 작업 모두 지원하며 데이터를 추가할때는 우선순위에 따라 적절한 위치에 삽입되며, 데이터를 제거할때는 항상 가장 높은 우선순위의 항목이 제거됩니다.<br>
이러한 우선순위큐를 구현하기 위해서 일반적으로 힙이라는 자료구조를 구현합니다.<br>
<br>
따라서 모든 정점은 자신의 자식 요소보다 우선순위가 높다는 성질과, 완전 이진 트리의 성질로 인해 삽입,삭제 시 O(logN)의 시간복잡도를 보입니다.<br>
또한 우선순위가 가장 높은 요소는 루트에 위치하므로, 이를 조회하는데에는 상수의 시간이 걸립니다.<br>
<br>
참고 - 힙은 형제노드와 대소 비교를 안함<br>
</details>

<details markdown = "1">
<summary>우선순위큐를 힙이 아닌 다른 자료구조로 구현한다면 어떻게 될까요?</summary>
힙이 아닌 배열 이나 연결리스트를 통해서도 구현할 수 있습니다.<br>
배열로 구현시, 배열의 새로운 요소를 추가하는 것은 O(1)의 시간복잡도를 가지며, 새 요소는 배열의 마지막에 추가됩니다.<br>
삭제시에는 가장 우선순위가 높은 요소를 찾아 삭제하는데 O(N)의 시간복잡도를 가집니다.(모든 요소 탐색)
조회 또한 가장 우선 순위가 높은 요소를 찾는데 O(N)의 시간복잡도를 가집니다.<br>
연결리스트로 구현시 삽입에 O(1)시간복잡도를 가집니다.(새 요소는 리스트의 시작 또는 끝에 삽입됨)<br>
삭제 시에는 O(N)이 걸립니다(전체 탐색)<br>
조회의 경우에도 O(N)의 시간복잡도를 가집니다.(전체 탐색)<br>
</details>

<details markdown = "1">
<summary>덱(deque)에 대해 설명해주세요</summary>
덱(Deque)은 "Double-Ended Queue"의 줄임말로, 앞과 뒤에서 데이터의 삽입과 삭제가 모두 가능한 자료구조입니다. 이 특성 때문에 덱은 큐(Queue)와 스택(Stack)의 연산을 모두 지원합니다. 덱은 유연성이 높아서 필요에 따라 스택처럼 Last-In-First-Out(LIFO) 방식으로 동작하게 할 수도 있고, 큐처럼 First-In-First-Out(FIFO) 방식으로 동작하게 할 수도 있습니다.
</details>

<details markdown = "1">
<summary>hash와 hash Function이 무엇인지 설명해주세요</summary>
Hash란 일반적으로 key가 Hash Function을 통과하여 암호화되어 나온 결과물을 의미하고, Hash Function은 임의의 길이의 입력값을 고정된 길이의 암호화된 출력으로 변환해 주는 함수를 뜻합니다.<br>
이러한 해시 함수는 어떤 입력 값에도 항상 고정된 길이의 해시값을 출력하고, 입력 값이 아주 일부만 변경되어도 전혀 다른 결과값을 출력하는 특징을 가집니다.(즉 출력물로 유추 불가)<br>
<br><br>
참고 - 왜 사용할까??<br>
해시 함수를 사용하면 원하는 데이터를 찾는데 필요한 시간을 줄일 수 있습니다.<br>
예를들어 배열에서 특정 값을 찾으려면 보통 원하는 값을 찾을때 까지 배열의 모든 요소를 탐색해야 하므로 시간이 오래걸릴 수 있습니다.<br>
하지만 해시 테이블을 사용한다고 하면, 특정 키의 해시 값을 계산하여 바로 해당 위치에 접근할 수 있으므로, 상대적으로 빠른 시간안에 원하는 값을 찾을 수 있습니다.<br>
<br>
또한 해시 함수는 단방향성을 가지므로, 해시 값을 통해 유추가 어려워 데이터의 보안성 또한 높일 수 있다.<br>
<br><br>
Constant Time Complexity: 해시 테이블에서 데이터의 조회, 삽입, 삭제 연산은 일반적으로 평균 시간 복잡도가 O(1)입니다. 즉, 데이터의 양에 관계없이 거의 일정한 시간이 걸립니다.
Direct Access: 해시 함수의 결과값은 배열의 인덱스처럼 사용됩니다. 이 인덱스를 사용해서 직접 해당 위치에 접근할 수 있기 때문에 데이터를 빠르게 찾을 수 있습니다.
</details>

<details markdown = "1">
<summary>해시 충돌이 무엇인지 혹시 아시나요?</summary>
해시 충돌이란 입력한 키 값이 다름에도 불구하고, 같은 해시값이 나오는 경우를 의미합니다.
</details>

<details markdown = "1">
<summary>이러한 해시 충돌은 불가피한것인가요??</summary>
일반적으로 해시 충돌은 불가피한 현상입니다. 저는 이 이유를 비둘기집 원리와 함께 설명드리고자 합니다.<br>
비들기집 원리는 간단히 말해서, 만약 n개의 비둘기집에 n+1마리의 비둘기가 있다면, 적어도 하나의 비둘기 집에는 두마리 이상의 비둘기가 있다는 원리입니다.<br>
해시함수의 경우, 일정한 크기의 해시 테이블에 많은 입력을 매핑해야 하는 상황에서 이 원리가 적용됩니다.<br>
즉, 한정된 수의 버킷에 무한히 많은 키를 매핑해야하는데, 이 경우엔 어떤 해시 함수를 사용하더라도 충돌은 불가피 합니다.<br>
물론, 실제로는 무한히 많은 키를 다루는 것은 아니지만, 주어진 입력 데이터의 가능한 모든 조합이 해시 테이블의 슬롯 수보다 많을 가능성이 높습니다.<br>
예를들어 문자열을 키로 사용한다고 가정해 보겠습니다. 문자열은 알파벳,숫자,특수 문자등 다양한 문자의 조합으로 이루어질 수 있고, 그 길이에도 제한이 없습니다.<br>
이렇게 가능한 조합이 거의 무한대에 가까운 데이터를 키로 사용할때, 이를 저장하기 위한 해시 테이블의 크기를 그만큼 무한대에 가까운크기로 만들 수 없습니다.<br>
따라서 해시 함수와 해시 테이블의 설계 과정에서 충돌을 최소화하는 것이 중요하며, 이를 효과적으로 처리하는 방법을 갖추는 것이 중요합니다.<br>
</details>

<details markdown = "1">
<summary>해시 충돌을 해결하는 방법에 대해 가능한 상세히 설명해주세요.</summary>
해시 충돌(안 일어난다면 탐색,삽입,삭제 연산이 모두 O(1))을 해결하는 대표적인 방법에는 개방 주소법(Open Addressing)과 분리 연결법이 있습니다.<br>
개방 주소법은 한 버킷에 오직 하나의 엔트리만 저장되는 방식으로, 충돌 발생 시 다른 버킷에 데이터를 저장합니다..<br>
충돌이 발생한 경우 probing을 바탕으로 다음 슬롯을 찾아가는데, 이러한 probing 방법에는 선형 탐사법, 제곱 탐사법, 이중 해싱 등이 있습니다.<br>
<br>
분리 연결법(Seperate Chaining)은 개방 주소법과 달리 한 버킷 당 들어갈 수 있는 엔트리 수에 제한을 두지 않는 방식입니다.<br>
이는 해시 충돌이 일어난 경우 해당 버킷에 연결된 리스트에 데이터를 추가합니다.<br>
하지만 개방 주소법에 비해 추가적인 메모리 공간(다음 노드를 가리키는 포인터 공간)이 필요합니다.<br>
<br>
지금까지 설명드린 두가지 방법외에도, (해시 테이블의 Load Factor가 높은 경우엔) 크기가 더 큰 새로운 테이블을 만들어 기존 데이터를 옮겨 사용하거나<br>
체이닝 방법을 통해 연결리스트가 너무 길어졌다면, 재해싱을 통해서 너무 길어진 리스트의 길이를 나누어 다시 저장하는 방법도 있습니다.<br>
<br><br>
데이터가 적은 경우엔 일반적으로 개방 주소법이 더 빠릅니다.(충돌이 발생해도 추가적인 메모리 공간 없이 원래 해시테이블 내에서 충돌을 해결하기에)<br>
<br>
부가 내용들<br>
선형 탐사법 : 해시 충돌이 일어난 경우, 해시값에서 고정된 폭만큼 옮겨 다음 빈칸을 찾는 방법<br>
-> 간단하지만 테이블의 연속된 공간에 데이터가 몰리고, 같은 해시값이 나올수록 탐색 효율이 계속 나빠짐.(해시 충돌이 해시 값 전체에 균등한 경우 유용)<br>
<br>
제곱 탐사법 : 탐사폭이 제곱으로 늘어남.(ex: 2의 1제곱, 2제곱 ~~~~)<br>
데이터가 메모리 공간에 균등하게 분포되지 않고, 특정 제곱값에만 집중될 수 있음.(탐색의 연쇄적 충돌은 선형보단 덜함)<br>
<br>
이중 해싱(로드 팩터 높은 경우) : 충돌 시 항목을 저장할 다음 위치를 결정할때, 원래 해시 함수와 다른 별개의 해시 함수를 사용하는 방법<br>
이 방법은 이전 방법에 비해 균일하게 데이터를 분포시킬 수 있습니다.하지만 두번째 해시 함수를 통해 새로운 해시값을 생성해서 추가 연산을 요구하게 되며, 이를 바탕으로 탐색 경로를 설정하기에, 빈 슬롯을 찾기 위해 메모리 내 여러 위치를 불규칙하게 접근하게 됩니다.<br>
<br>
<br>
Load Factor(적재율)는 해시 테이블에서 현재 저장된 엔트리의 수와, 해시 테이블의 전체 버킷수의 비율을 나타냄(엔트리수 / 전체 버킷 수)<br>
load factor가 1에 가까워질수록 충돌 확률 증가, 로드 팩터가 높다면 보통 재해싱을 통해 더 큰 크기로 확장.(즉 새로운 버킷에 재배치)<br>
반면 너무 낮다면 메모리 사용이 비효율적일 수 있다.<br>
<br>
 해시 테이블의 기본 개념을 간단히 되짚어보면, 해시 테이블은 키를 입력으로 받아 해시 함수를 통해 해당 키에 대한 인덱스 값을 생성하고, 그 인덱스에 해당하는 위치에 값을 저장하는 자료구조<br>
<br>
체이닝으로 충돌을 해결하면, (리스트로 데이터가 저장되어있기에) 원하는 값을 찾기 위해 해당 인덱스(해시값)에 연결된 모든 키를 확인해야 될 수 있다.(탐색 및 삭제에 O(k : 키의 갯수))<br>
참고 - 충돌이 일어나지 않는다면, 즉 각각의 키가 유일한 해시값을 가진다면, 탐색+삽입+삭제는 O(1)<br>
참고 - 개방 주소법으로 해결하면 탐색 및 삭제의 시간 복잡도는 로드 팩터에 비례합니다.<br>
</details>




